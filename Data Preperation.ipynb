{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling ETF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_excel('etf_corp_actions.xlsx', sheet_name = 'SPLITS')\n",
    "def adjust_splits(spy,ticker):\n",
    "    test = spy.copy()\n",
    "    if ticker in splits['symbol'].unique():\n",
    "        splits_df = splits[splits['symbol']==ticker].sort_values(by = 'split_date').copy()\n",
    "        splits_df['raw_adj_split'] = splits_df.groupby('symbol')['split'].cumprod()\n",
    "\n",
    "        adjustments = []\n",
    "        for x in range(len(splits_df)):\n",
    "\n",
    "            start_date = splits_df.iloc[x,1]\n",
    "\n",
    "            if x+1 == len(splits_df):\n",
    "                end_date = test['DATE'].iloc[-1] + timedelta(days = 1)\n",
    "            else:\n",
    "                end_date = splits_df.iloc[x+1,1]\n",
    "            split_ratio = splits_df.iloc[x,3]\n",
    "            updated = test[(test['DATE']>=start_date)&(test['DATE']<end_date)].drop(['DATE','last_vol'], axis = 1)\n",
    "            updated_col = updated.columns\n",
    "            updated = updated/split_ratio\n",
    "            adjustments.append(updated)\n",
    "        adj_df = pd.concat(adjustments)\n",
    "        # Update the original dataframe\n",
    "        test.loc[adj_df.index, updated_col] = adj_df\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['SPY','IJH','IWM','QQQ','DIA',\n",
    "            'EWJ','EWY','EWC','EWU','EWA','EWG','EWZ',\n",
    "           'GLD','SLV',\n",
    "           'DBE','DBA','DBB']\n",
    "data_dict = {}\n",
    "\n",
    "for symbol in tickers:\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&outputsize=full&apikey={your_AV_key}\"\n",
    "    data = pd.DataFrame(requests.get(url).json()['Time Series (Daily)']).T.sort_index().reset_index()\n",
    "    data = data.rename(columns={'index': 'DATE', '4. close':'last_close',\n",
    "                                '1. open':'last_open', '2. high':'last_max','3. low':'last_min',\n",
    "                                '5. volume':'last_vol'})\n",
    "    data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "    data[data.columns[1:]] = data[data.columns[1:]].astype(float)\n",
    "    #data.loc[:,'TICKER'] = symbol\n",
    "    data = adjust_splits(data,symbol)\n",
    "    data.to_pickle(symbol+'_daily.pkl')\n",
    "    data_dict[symbol] = data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_class(df):\n",
    "    df['CLASS'] = np.where((df['last_max']>df['last_max'].shift(1))&(df['last_min']>df['last_min'].shift(1)),\n",
    "                           np.where(df['last_close']>df['last_open'],'U_UP','D_UP'),\n",
    "                np.where((df['last_max']<df['last_max'].shift(1))&(df['last_min']<df['last_min'].shift(1)),\n",
    "                         np.where(df['last_close']<df['last_open'],'D_DOWN','U_DOWN'),\n",
    "                np.where(((df['last_max']>=df['last_max'].shift(1))&(df['last_min']<=df['last_min'].shift(1))),\n",
    "                            np.where(df['last_close']>=df['last_open'], 'U_OUT','D_OUT'),\n",
    "                np.where((df['last_max']<=df['last_max'].shift(1))&(df['last_min']>=df['last_min'].shift(1)),\n",
    "                         np.where(df['last_close']>=df['last_open'], 'U_IN','D_IN'),'CHECK'))))\n",
    "    df['LABEL'] = df['CLASS'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Lag Features\n",
    "5 Day, 10 Day, 20 Day, 40 Day, 60 Day, and 120 Day:\n",
    "- ROC (OHLC)\n",
    "- % to N-day max/min\n",
    "- Coefficient of Variation of Returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag_features(df):\n",
    "    for lb in lookbacks:\n",
    "        # OHLC ROC\n",
    "        df['ROC_CLOSE_'+str(lb)]=(df['last_close']/df['last_close'].shift(lb))-1\n",
    "        df['ROC_OPEN_'+str(lb)]=(df['last_open']/df['last_open'].shift(lb))-1\n",
    "        df['ROC_HIGH_'+str(lb)]=(df['last_max']/df['last_max'].shift(lb))-1\n",
    "        df['ROC_LOW_'+str(lb)]=(df['last_min']/df['last_min'].shift(lb))-1\n",
    "\n",
    "        # OHLC % to MIN/MAX\n",
    "        df['CLOSE_MIN_'+str(lb)] = (df['last_close'] / df.rolling(lb)['last_close'].min().shift(1))-1\n",
    "        df['CLOSE_MAX_'+str(lb)] = (df['last_close'] / df.rolling(lb)['last_close'].max().shift(1))-1\n",
    "        df['OPEN_MIN_'+str(lb)] = (df['last_open'] / df.rolling(lb)['last_open'].min().shift(1))-1\n",
    "        df['OPEN_MAX_'+str(lb)] = (df['last_open'] / df.rolling(lb)['last_open'].max().shift(1))-1\n",
    "        df['LOW_MIN_'+str(lb)] = (df['last_min'] / df.rolling(lb)['last_min'].min().shift(1))-1\n",
    "        df['LOW_MAX_'+str(lb)] = (df['last_min'] / df.rolling(lb)['last_min'].max().shift(1))-1\n",
    "        df['HIGH_MIN_'+str(lb)] = (df['last_max'] / df.rolling(lb)['last_max'].min().shift(1))-1\n",
    "        df['HIGH_MAX_'+str(lb)] = (df['last_max'] / df.rolling(lb)['last_max'].max().shift(1))-1\n",
    "\n",
    "        # CV\n",
    "        df['CV_'+str(lb)] = df.rolling(lb)['last_close'].std()/df.rolling(lb)['last_close'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['SPY','IJH','IWM','QQQ','DIA',\n",
    "            'EWJ','EWY','EWC','EWU','EWA','EWG','EWZ',\n",
    "           'GLD','SLV',\n",
    "           'DBE','DBA','DBB']\n",
    "data_dict = {}\n",
    "\n",
    "for symbol in tickers:\n",
    "    data = pd.read_pickle(symbol+'_daily.pkl')\n",
    "    data_dict[symbol] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookbacks = [5,10,20,40,60,120]\n",
    "label_mapping = {'U_UP': 0, 'D_UP': 1, 'D_DOWN': 2, 'U_DOWN': 3, 'U_OUT': 4, 'D_OUT': 5, 'U_IN': 6, 'D_IN': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in tickers:\n",
    "    get_price_class(data_dict[symbol])\n",
    "    get_lag_features(data_dict[symbol])\n",
    "\n",
    "    if data_dict[symbol].loc[0,'CLASS'] != 'CHECK':\n",
    "        print('check: '+symbol)\n",
    "    else:\n",
    "        # Remove CHECK (First Row)\n",
    "        data_dict[symbol] = data_dict[symbol].iloc[1:]\n",
    "        data_dict[symbol] = pd.get_dummies(data_dict[symbol],columns = ['CLASS'], drop_first= True)\n",
    "        data_dict[symbol] = data_dict[symbol].drop(['DATE','last_open','last_max','last_close','last_min','last_vol'], axis = 1).dropna()\n",
    "        data_dict[symbol]['LABEL'] = data_dict[symbol]['LABEL'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_equity = ['SPY', 'IJH', 'QQQ', 'DIA', 'IWM']\n",
    "intl_equity = ['EWJ', 'EWY', 'EWC', 'EWA', 'EWG', 'EWZ']\n",
    "prec_metal = ['GLD','SLV']\n",
    "comm = ['DBA','DBE','DBB']\n",
    "use_df = pd.concat([data_dict[symbol] for symbol in us_equity], ignore_index=True)\n",
    "ine_df = pd.concat([data_dict[symbol] for symbol in intl_equity], ignore_index=True)\n",
    "pm_df = pd.concat([data_dict[symbol] for symbol in prec_metal], ignore_index=True)\n",
    "com_df = pd.concat([data_dict[symbol] for symbol in comm], ignore_index=True)\n",
    "sp_df = data_dict['SPY'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_df.to_pickle('US_EQUITY.pkl')\n",
    "ine_df.to_pickle('INTL_EQUITY.pkl')\n",
    "pm_df.to_pickle('PREC_METAL.pkl')\n",
    "com_df.to_pickle('COMM.pkl')\n",
    "sp_df.to_pickle('SPY.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
